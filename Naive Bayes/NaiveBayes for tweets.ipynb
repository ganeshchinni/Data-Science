{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2413f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweets=pd.read_csv(r\"C:\\data\\data science\\Study material\\Machine learning classifiers (Naive bayes)\\Datasets_Naive Bayes\\Disaster_tweets_NB.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3ac8a46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f572b1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6778fbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates=tweets.duplicated()\n",
    "sum(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "86e183e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data\n",
    "import re\n",
    "stop_words=[]\n",
    "#loading the custom build stop words\n",
    "with open(\"C:\\data\\data science\\Study material\\Text Mining and sentiment analysis\\Datasets NLP\\stopwords_en.txt\") as sw:\n",
    "    stop_words=sw.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0e974f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=stop_words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "68fa65f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(i):\n",
    "    i = re.sub(\"[^A-Za-z\" \"]+\",\" \",i).lower()\n",
    "    i = re.sub(\"[0-9\" \"]+\",\" \",i)\n",
    "    w = []\n",
    "    for word in i.split(\" \"):\n",
    "        if len(word)>3:\n",
    "            w.append(word)\n",
    "    return (\" \".join(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e28c609c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hope having good week just checking'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_text(\"Hope you are having a good week. Just checking in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "cb57c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.text=tweets.text.apply(cleaning_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "aaa81fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds reason this earthquake allah forgive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residents asked shelter place being notified o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just sent this photo from ruby alaska smoke fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>giant cranes holding bridge collapse into near...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aria ahrary thetawniest control wild fires cal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>volcano hawaii http zdtoyd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police investigating after bike collided with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>latest more homes razed northern california wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0            deeds reason this earthquake allah forgive       1  \n",
       "1                    forest fire near ronge sask canada       1  \n",
       "2     residents asked shelter place being notified o...       1  \n",
       "3     people receive wildfires evacuation orders cal...       1  \n",
       "4     just sent this photo from ruby alaska smoke fr...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  giant cranes holding bridge collapse into near...       1  \n",
       "7609  aria ahrary thetawniest control wild fires cal...       1  \n",
       "7610                         volcano hawaii http zdtoyd       1  \n",
       "7611  police investigating after bike collided with ...       1  \n",
       "7612  latest more homes razed northern california wi...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "26d6ff96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing empty rows\n",
    "tweets = tweets.loc[tweets.text != \" \",:]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d4023d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c60c0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "newtweets=tweets.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f557d4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "keyword     0\n",
       "location    0\n",
       "text        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtweets.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "484d6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "# Convert a collection of text documents to a matrix of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "929407cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into test and train sets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f9a1f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train,tweets_test=train_test_split(newtweets,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d1425d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a matrixof token counts for the entire text doc.\n",
    "def split_into_words (i):\n",
    "    return [word for word in i.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "029960af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the preparation of tweets texts into word count matrix format - Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "tweets_bow = CountVectorizer(analyzer = split_into_words).fit(newtweets.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "22162e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining bow for all text messages\n",
    "all_newtweets=tweets_bow.transform(newtweets.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fe9042d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training messages\n",
    "train_tweets_matrix = tweets_bow.transform(tweets_train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "77cf13ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing messages\n",
    "test_tweets_matrix = tweets_bow.transform(tweets_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "50eb32c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Term weighting and normalizing on entire emails\n",
    "tfidf_transformer = TfidfTransformer().fit(all_newtweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "61d9a24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4064, 23937)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing TFIDF for train emails\n",
    "train_tfidf = tfidf_transformer.transform(train_tweets_matrix)\n",
    "train_tfidf.shape # (row, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "17093801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1016, 23937)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing TFIDF for test emails\n",
    "test_tfidf = tfidf_transformer.transform(test_tweets_matrix)\n",
    "test_tfidf.shape #  (row, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c7cae830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a naive bayes model on training data set \n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB as MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4c330e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "classifier_mb = MB()\n",
    "classifier_mb.fit(train_tfidf, tweets_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0a017ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7736220472440944"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation on Test Data\n",
    "test_pred_m = classifier_mb.predict(test_tfidf)\n",
    "accuracy_test_m = np.mean(test_pred_m == tweets_test.target)\n",
    "accuracy_test_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "61717610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7736220472440944"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_pred_m, tweets_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "1e781950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>548</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target    0    1\n",
       "row_0           \n",
       "0       548  200\n",
       "1        30  238"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test_pred_m, tweets_test.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "38369117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9124015748031497"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data accuracy\n",
    "train_pred_m = classifier_mb.predict(train_tfidf)\n",
    "accuracy_train_m = np.mean(train_pred_m == tweets_train.target)\n",
    "accuracy_train_m\n",
    "\n",
    "# Multinomial Naive Bayes changing default alpha for laplace smoothing\n",
    "# if alpha = 0 then no smoothing is applied and the default alpha parameter is 1\n",
    "# the smoothing process mainly solves the emergence of zero probability problem in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7de8943e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=3)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_mb_lap = MB(alpha = 3)\n",
    "classifier_mb_lap.fit(train_tfidf, tweets_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "547da7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7273622047244095"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation on Test Data after applying laplace\n",
    "test_pred_lap = classifier_mb_lap.predict(test_tfidf)\n",
    "accuracy_test_lap = np.mean(test_pred_lap == tweets_test.target)\n",
    "accuracy_test_lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "bae7ab2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7273622047244095"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_pred_lap, tweets_test.target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "822f7bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8368602362204725"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test_pred_lap, tweets_test.target)\n",
    "\n",
    "# Training Data accuracy\n",
    "train_pred_lap = classifier_mb_lap.predict(train_tfidf)\n",
    "accuracy_train_lap = np.mean(train_pred_lap == tweets_train.target)\n",
    "accuracy_train_lap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88271da0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
